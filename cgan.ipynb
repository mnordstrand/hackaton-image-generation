{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import expand_dims\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randn\n",
    "from numpy.random import randint\n",
    "from numpy import asarray\n",
    "from keras.datasets.fashion_mnist import load_data\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Concatenate\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone discriminator model\n",
    "def define_discriminator(in_shape=(28,28,3), n_classes=11):\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # scale up to image dimensions with linear activation\n",
    "    n_nodes = in_shape[0] * in_shape[1] * in_shape[2]\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((in_shape[0], in_shape[1], in_shape[2]))(li)\n",
    "    # image input\n",
    "    in_image = Input(shape=in_shape)\n",
    "    # concat label as a channel\n",
    "    merge = Concatenate()([in_image, li])\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(merge)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # downsample\n",
    "    fe = Conv2D(128, (3,3), strides=(2,2), padding='same')(fe)\n",
    "    fe = LeakyReLU(alpha=0.2)(fe)\n",
    "    # flatten feature maps\n",
    "    fe = Flatten()(fe)\n",
    "    # dropout\n",
    "    fe = Dropout(0.4)(fe)\n",
    "    # output\n",
    "    out_layer = Dense(1, activation='sigmoid')(fe)\n",
    "    # define model\n",
    "    model = Model([in_image, in_label], out_layer)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_classes=11):\n",
    "    # label input\n",
    "    in_label = Input(shape=(1,))\n",
    "    # embedding for categorical input\n",
    "    li = Embedding(n_classes, 50)(in_label)\n",
    "    # linear multiplication\n",
    "    n_nodes = 7 * 7\n",
    "    li = Dense(n_nodes)(li)\n",
    "    # reshape to additional channel\n",
    "    li = Reshape((7, 7, 1))(li)\n",
    "    # image generator input\n",
    "    in_lat = Input(shape=(latent_dim,))\n",
    "    # foundation for 7x7 image\n",
    "    n_nodes = 128 * 7 * 7\n",
    "    gen = Dense(n_nodes)(in_lat)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    gen = Reshape((7, 7, 128))(gen)\n",
    "    # merge image gen and label input\n",
    "    merge = Concatenate()([gen, li])\n",
    "    # upsample to 14x14\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    # upsample to 28x28\n",
    "    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n",
    "    gen = LeakyReLU(alpha=0.2)(gen)\n",
    "    # output\n",
    "    out_layer = Conv2D(3, (7,7), activation='tanh', padding='same')(gen)\n",
    "    # define model\n",
    "    model = Model([in_lat, in_label], out_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(g_model, d_model):\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # get noise and label inputs from generator model\n",
    "    gen_noise, gen_label = g_model.input\n",
    "    # get image output from the generator model\n",
    "    gen_output = g_model.output\n",
    "    # connect image output and label input from generator as inputs to discriminator\n",
    "    gan_output = d_model([gen_output, gen_label])\n",
    "    # define gan model as taking noise and label and outputting a classification\n",
    "    model = Model([gen_noise, gen_label], gan_output)\n",
    "    # compile model\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(file_name, index):\n",
    "    parts = tf.strings.split(file_name, os.sep)\n",
    "    #label = parts[-2].numpy()\n",
    "    label = index\n",
    "\n",
    "    image = tf.io.read_file(file_name)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32).numpy()\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_samples(path):\n",
    "    folder_list = tf.io.gfile.listdir(path)\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i, folder in enumerate(folder_list):\n",
    "        file_list = tf.io.gfile.listdir(path + folder)\n",
    "        for file_name in file_list:\n",
    "            image, label = parse_image(path + folder + file_name, i)\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return [np.array(images), np.array(labels, dtype=np.int8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select real samples\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    # split into images and labels\n",
    "    images, labels = dataset\n",
    "    # choose random instances\n",
    "    ix = randint(0, images.shape[0], n_samples)\n",
    "    # select images and labels\n",
    "    X, labels = images[ix], labels[ix]\n",
    "    # generate class labels\n",
    "    y = ones((n_samples, 1))\n",
    "    return [X, labels], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples, n_classes=11):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n_samples)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    z_input = x_input.reshape(n_samples, latent_dim)\n",
    "    # generate labels\n",
    "    labels = randint(0, n_classes, n_samples)\n",
    "    return [z_input, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n_samples):\n",
    "    # generate points in latent space\n",
    "    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    images = generator.predict([z_input, labels_input])\n",
    "    # create class labels\n",
    "    y = zeros((n_samples, 1))\n",
    "    return [images, labels_input], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=5, n_batch=32):\n",
    "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(bat_per_epo):\n",
    "            # get randomly selected 'real' samples\n",
    "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
    "            # generate 'fake' examples\n",
    "            [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
    "            # summarize loss on this batch\n",
    "            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' %\n",
    "                (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n",
    "    # save the generator model\n",
    "    g_model.save('cgan_generator.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "\n",
    "d_model = define_discriminator()\n",
    "\n",
    "\"\"\"\n",
    "tf.keras.utils.plot_model(\n",
    "    d_model,\n",
    "    to_file=\"discriminator.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "g_model = define_generator(latent_dim)\n",
    "\n",
    "\"\"\"\n",
    "tf.keras.utils.plot_model(\n",
    "    g_model,\n",
    "    to_file=\"generator.png\",\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    ")\n",
    "\"\"\"\n",
    "gan_model = define_gan(g_model, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_real_samples('gs://emanuel-aa-sandbox/hackathon-training-data-generation-small/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">1, 1/50, d1=0.758, d2=0.694 g=0.693\n",
      ">1, 2/50, d1=0.654, d2=0.699 g=0.689\n",
      ">1, 3/50, d1=0.564, d2=0.707 g=0.680\n",
      ">1, 4/50, d1=0.455, d2=0.723 g=0.664\n",
      ">1, 5/50, d1=0.382, d2=0.753 g=0.636\n",
      ">1, 6/50, d1=0.286, d2=0.800 g=0.595\n",
      ">1, 7/50, d1=0.254, d2=0.887 g=0.552\n",
      ">1, 8/50, d1=0.225, d2=0.988 g=0.485\n",
      ">1, 9/50, d1=0.250, d2=1.106 g=0.454\n",
      ">1, 10/50, d1=0.251, d2=1.161 g=0.453\n",
      ">1, 11/50, d1=0.295, d2=1.142 g=0.472\n",
      ">1, 12/50, d1=0.328, d2=1.041 g=0.534\n",
      ">1, 13/50, d1=0.412, d2=0.932 g=0.638\n",
      ">1, 14/50, d1=0.485, d2=0.773 g=0.747\n",
      ">1, 15/50, d1=0.556, d2=0.680 g=0.806\n",
      ">1, 16/50, d1=0.545, d2=0.621 g=0.902\n",
      ">1, 17/50, d1=0.639, d2=0.574 g=0.948\n",
      ">1, 18/50, d1=0.661, d2=0.514 g=1.019\n",
      ">1, 19/50, d1=0.648, d2=0.478 g=1.070\n",
      ">1, 20/50, d1=0.697, d2=0.487 g=1.098\n",
      ">1, 21/50, d1=0.696, d2=0.458 g=1.151\n",
      ">1, 22/50, d1=0.801, d2=0.453 g=1.069\n",
      ">1, 23/50, d1=0.700, d2=0.481 g=1.182\n",
      ">1, 24/50, d1=0.699, d2=0.432 g=1.249\n",
      ">1, 25/50, d1=0.749, d2=0.389 g=1.183\n",
      ">1, 26/50, d1=0.711, d2=0.404 g=1.239\n",
      ">1, 27/50, d1=0.769, d2=0.402 g=1.232\n",
      ">1, 28/50, d1=0.674, d2=0.378 g=1.263\n",
      ">1, 29/50, d1=0.757, d2=0.398 g=1.179\n",
      ">1, 30/50, d1=0.735, d2=0.395 g=1.174\n",
      ">1, 31/50, d1=0.619, d2=0.401 g=1.347\n",
      ">1, 32/50, d1=0.709, d2=0.378 g=1.290\n",
      ">1, 33/50, d1=0.676, d2=0.400 g=1.407\n",
      ">1, 34/50, d1=0.741, d2=0.412 g=1.281\n",
      ">1, 35/50, d1=0.659, d2=0.350 g=1.379\n",
      ">1, 36/50, d1=0.764, d2=0.333 g=1.313\n",
      ">1, 37/50, d1=0.588, d2=0.352 g=1.338\n",
      ">1, 38/50, d1=0.594, d2=0.393 g=1.380\n",
      ">1, 39/50, d1=0.609, d2=0.352 g=1.565\n",
      ">1, 40/50, d1=0.658, d2=0.334 g=1.482\n",
      ">1, 41/50, d1=0.634, d2=0.314 g=1.506\n",
      ">1, 42/50, d1=0.721, d2=0.361 g=1.431\n",
      ">1, 43/50, d1=0.712, d2=0.382 g=1.372\n",
      ">1, 44/50, d1=0.663, d2=0.333 g=1.437\n",
      ">1, 45/50, d1=0.568, d2=0.365 g=1.431\n",
      ">1, 46/50, d1=0.609, d2=0.288 g=1.424\n",
      ">1, 47/50, d1=0.535, d2=0.307 g=1.584\n",
      ">1, 48/50, d1=0.586, d2=0.296 g=1.567\n",
      ">1, 49/50, d1=0.574, d2=0.349 g=1.517\n",
      ">1, 50/50, d1=0.519, d2=0.296 g=1.649\n",
      ">2, 1/50, d1=0.717, d2=0.318 g=1.565\n",
      ">2, 2/50, d1=0.572, d2=0.336 g=1.537\n",
      ">2, 3/50, d1=0.429, d2=0.263 g=1.700\n",
      ">2, 4/50, d1=0.665, d2=0.301 g=1.660\n",
      ">2, 5/50, d1=0.595, d2=0.379 g=1.710\n",
      ">2, 6/50, d1=0.379, d2=0.269 g=1.698\n",
      ">2, 7/50, d1=0.754, d2=0.322 g=1.563\n",
      ">2, 8/50, d1=0.377, d2=0.324 g=1.676\n",
      ">2, 9/50, d1=0.699, d2=0.328 g=1.671\n",
      ">2, 10/50, d1=0.561, d2=0.269 g=1.665\n",
      ">2, 11/50, d1=0.474, d2=0.324 g=1.702\n",
      ">2, 12/50, d1=0.489, d2=0.280 g=1.900\n",
      ">2, 13/50, d1=0.523, d2=0.224 g=1.784\n",
      ">2, 14/50, d1=0.370, d2=0.220 g=1.846\n",
      ">2, 15/50, d1=0.307, d2=0.286 g=2.095\n",
      ">2, 16/50, d1=0.454, d2=0.235 g=1.865\n",
      ">2, 17/50, d1=0.555, d2=0.258 g=1.901\n",
      ">2, 18/50, d1=0.391, d2=0.230 g=2.073\n",
      ">2, 19/50, d1=0.501, d2=0.236 g=2.014\n",
      ">2, 20/50, d1=0.394, d2=0.249 g=2.108\n",
      ">2, 21/50, d1=0.470, d2=0.193 g=1.815\n",
      ">2, 22/50, d1=0.540, d2=0.320 g=1.961\n",
      ">2, 23/50, d1=0.559, d2=0.203 g=1.853\n",
      ">2, 24/50, d1=0.351, d2=0.282 g=1.843\n",
      ">2, 25/50, d1=0.490, d2=0.250 g=1.807\n",
      ">2, 26/50, d1=0.437, d2=0.280 g=1.845\n",
      ">2, 27/50, d1=0.332, d2=0.222 g=2.223\n",
      ">2, 28/50, d1=0.332, d2=0.250 g=2.220\n",
      ">2, 29/50, d1=0.523, d2=0.203 g=2.106\n",
      ">2, 30/50, d1=0.391, d2=0.214 g=2.001\n",
      ">2, 31/50, d1=0.351, d2=0.226 g=2.214\n",
      ">2, 32/50, d1=0.261, d2=0.143 g=2.119\n",
      ">2, 33/50, d1=0.532, d2=0.340 g=2.029\n",
      ">2, 34/50, d1=0.771, d2=0.192 g=2.192\n",
      ">2, 35/50, d1=0.213, d2=0.256 g=2.127\n",
      ">2, 36/50, d1=0.266, d2=0.158 g=2.236\n",
      ">2, 37/50, d1=0.223, d2=0.162 g=2.319\n",
      ">2, 38/50, d1=0.399, d2=0.191 g=2.316\n",
      ">2, 39/50, d1=0.257, d2=0.134 g=2.260\n",
      ">2, 40/50, d1=0.265, d2=0.188 g=2.484\n",
      ">2, 41/50, d1=0.381, d2=0.196 g=2.364\n",
      ">2, 42/50, d1=0.452, d2=0.331 g=2.465\n",
      ">2, 43/50, d1=0.316, d2=0.099 g=2.483\n",
      ">2, 44/50, d1=0.243, d2=0.130 g=2.292\n",
      ">2, 45/50, d1=0.566, d2=0.207 g=1.942\n",
      ">2, 46/50, d1=0.286, d2=0.293 g=2.021\n",
      ">2, 47/50, d1=0.344, d2=0.151 g=2.309\n",
      ">2, 48/50, d1=0.276, d2=0.178 g=2.360\n",
      ">2, 49/50, d1=0.357, d2=0.214 g=2.357\n",
      ">2, 50/50, d1=0.267, d2=0.145 g=2.500\n",
      ">3, 1/50, d1=0.366, d2=0.176 g=2.449\n",
      ">3, 2/50, d1=0.195, d2=0.144 g=2.431\n",
      ">3, 3/50, d1=0.256, d2=0.194 g=2.543\n",
      ">3, 4/50, d1=0.474, d2=0.148 g=2.272\n",
      ">3, 5/50, d1=0.118, d2=0.126 g=2.453\n",
      ">3, 6/50, d1=0.249, d2=0.138 g=2.735\n",
      ">3, 7/50, d1=0.404, d2=0.180 g=2.208\n",
      ">3, 8/50, d1=0.294, d2=0.173 g=2.379\n",
      ">3, 9/50, d1=0.480, d2=0.202 g=2.052\n",
      ">3, 10/50, d1=0.284, d2=0.272 g=2.273\n",
      ">3, 11/50, d1=0.381, d2=0.156 g=2.569\n",
      ">3, 12/50, d1=0.315, d2=0.213 g=2.435\n",
      ">3, 13/50, d1=0.281, d2=0.129 g=2.301\n",
      ">3, 14/50, d1=0.122, d2=0.122 g=2.735\n",
      ">3, 15/50, d1=0.385, d2=0.217 g=2.636\n",
      ">3, 16/50, d1=0.306, d2=0.132 g=2.351\n",
      ">3, 17/50, d1=0.188, d2=0.109 g=2.560\n",
      ">3, 18/50, d1=0.149, d2=0.140 g=2.698\n",
      ">3, 19/50, d1=0.164, d2=0.122 g=3.019\n",
      ">3, 20/50, d1=0.306, d2=0.171 g=2.781\n",
      ">3, 21/50, d1=0.208, d2=0.114 g=2.984\n",
      ">3, 22/50, d1=0.422, d2=0.156 g=2.843\n",
      ">3, 23/50, d1=0.064, d2=0.112 g=3.018\n",
      ">3, 24/50, d1=0.210, d2=0.095 g=2.821\n",
      ">3, 25/50, d1=0.045, d2=0.063 g=3.245\n",
      ">3, 26/50, d1=0.316, d2=0.115 g=3.059\n",
      ">3, 27/50, d1=0.259, d2=0.120 g=2.719\n",
      ">3, 28/50, d1=0.424, d2=0.236 g=2.640\n",
      ">3, 29/50, d1=0.137, d2=0.093 g=3.198\n",
      ">3, 30/50, d1=0.395, d2=0.115 g=2.685\n",
      ">3, 31/50, d1=0.161, d2=0.182 g=2.853\n",
      ">3, 32/50, d1=0.295, d2=0.121 g=2.550\n",
      ">3, 33/50, d1=0.342, d2=0.243 g=2.786\n",
      ">3, 34/50, d1=0.039, d2=0.091 g=3.504\n",
      ">3, 35/50, d1=0.307, d2=0.046 g=2.995\n",
      ">3, 36/50, d1=0.115, d2=0.060 g=2.763\n",
      ">3, 37/50, d1=0.120, d2=0.078 g=2.772\n",
      ">3, 38/50, d1=0.211, d2=0.242 g=3.048\n",
      ">3, 39/50, d1=0.128, d2=0.075 g=3.282\n",
      ">3, 40/50, d1=0.310, d2=0.074 g=2.872\n",
      ">3, 41/50, d1=0.094, d2=0.103 g=2.990\n",
      ">3, 42/50, d1=0.082, d2=0.061 g=3.166\n",
      ">3, 43/50, d1=0.322, d2=0.239 g=3.070\n",
      ">3, 44/50, d1=0.231, d2=0.057 g=3.262\n",
      ">3, 45/50, d1=0.113, d2=0.037 g=3.026\n",
      ">3, 46/50, d1=0.098, d2=0.070 g=2.943\n",
      ">3, 47/50, d1=0.295, d2=0.262 g=2.967\n",
      ">3, 48/50, d1=0.079, d2=0.055 g=3.202\n",
      ">3, 49/50, d1=0.205, d2=0.045 g=3.027\n",
      ">3, 50/50, d1=0.041, d2=0.067 g=3.237\n",
      ">4, 1/50, d1=0.054, d2=0.059 g=3.299\n",
      ">4, 2/50, d1=0.041, d2=0.112 g=3.601\n",
      ">4, 3/50, d1=0.455, d2=0.127 g=3.007\n",
      ">4, 4/50, d1=0.143, d2=0.103 g=3.163\n",
      ">4, 5/50, d1=0.151, d2=0.055 g=2.868\n",
      ">4, 6/50, d1=0.166, d2=0.087 g=3.261\n",
      ">4, 7/50, d1=0.186, d2=0.091 g=3.322\n",
      ">4, 8/50, d1=0.163, d2=0.089 g=3.487\n",
      ">4, 9/50, d1=0.129, d2=0.056 g=3.087\n",
      ">4, 10/50, d1=0.079, d2=0.071 g=3.515\n",
      ">4, 11/50, d1=0.066, d2=0.093 g=3.738\n",
      ">4, 12/50, d1=0.571, d2=0.133 g=2.704\n",
      ">4, 13/50, d1=0.027, d2=0.060 g=3.253\n",
      ">4, 14/50, d1=0.256, d2=0.098 g=2.771\n",
      ">4, 15/50, d1=0.094, d2=0.117 g=3.105\n",
      ">4, 16/50, d1=0.058, d2=0.052 g=3.701\n",
      ">4, 17/50, d1=0.148, d2=0.049 g=2.748\n",
      ">4, 18/50, d1=0.028, d2=0.091 g=3.679\n",
      ">4, 19/50, d1=0.143, d2=0.044 g=3.453\n",
      ">4, 20/50, d1=0.250, d2=0.367 g=4.116\n",
      ">4, 21/50, d1=0.280, d2=0.026 g=3.960\n",
      ">4, 22/50, d1=0.201, d2=0.048 g=3.293\n",
      ">4, 23/50, d1=0.461, d2=0.487 g=3.524\n",
      ">4, 24/50, d1=0.283, d2=0.046 g=3.888\n",
      ">4, 25/50, d1=0.174, d2=0.042 g=3.654\n",
      ">4, 26/50, d1=0.046, d2=0.045 g=3.534\n",
      ">4, 27/50, d1=0.181, d2=0.070 g=2.963\n",
      ">4, 28/50, d1=0.187, d2=0.128 g=3.016\n",
      ">4, 29/50, d1=0.093, d2=0.072 g=3.217\n",
      ">4, 30/50, d1=0.202, d2=0.081 g=3.091\n",
      ">4, 31/50, d1=0.039, d2=0.119 g=3.591\n",
      ">4, 32/50, d1=0.269, d2=0.052 g=3.201\n",
      ">4, 33/50, d1=0.105, d2=0.120 g=3.382\n",
      ">4, 34/50, d1=0.009, d2=0.034 g=3.848\n",
      ">4, 35/50, d1=0.162, d2=0.054 g=3.272\n",
      ">4, 36/50, d1=0.292, d2=0.253 g=3.317\n",
      ">4, 37/50, d1=0.143, d2=0.029 g=3.572\n",
      ">4, 38/50, d1=0.081, d2=0.044 g=3.482\n",
      ">4, 39/50, d1=0.164, d2=0.087 g=3.368\n",
      ">4, 40/50, d1=0.028, d2=0.054 g=3.761\n",
      ">4, 41/50, d1=0.048, d2=0.025 g=3.904\n",
      ">4, 42/50, d1=0.235, d2=0.123 g=3.615\n",
      ">4, 43/50, d1=0.033, d2=0.030 g=3.743\n",
      ">4, 44/50, d1=0.062, d2=0.053 g=3.694\n",
      ">4, 45/50, d1=0.008, d2=0.024 g=3.833\n",
      ">4, 46/50, d1=0.074, d2=0.038 g=3.744\n",
      ">4, 47/50, d1=0.082, d2=0.059 g=3.537\n",
      ">4, 48/50, d1=0.143, d2=0.186 g=4.252\n",
      ">4, 49/50, d1=0.354, d2=0.032 g=3.712\n",
      ">4, 50/50, d1=0.114, d2=0.039 g=3.649\n",
      ">5, 1/50, d1=0.157, d2=0.164 g=3.692\n",
      ">5, 2/50, d1=0.069, d2=0.028 g=3.849\n",
      ">5, 3/50, d1=0.040, d2=0.024 g=3.950\n",
      ">5, 4/50, d1=0.252, d2=0.109 g=3.450\n",
      ">5, 5/50, d1=0.053, d2=0.101 g=3.615\n",
      ">5, 6/50, d1=0.017, d2=0.014 g=4.344\n",
      ">5, 7/50, d1=0.092, d2=0.030 g=3.710\n",
      ">5, 8/50, d1=0.024, d2=0.037 g=3.908\n",
      ">5, 9/50, d1=0.059, d2=0.036 g=3.409\n",
      ">5, 10/50, d1=0.048, d2=0.032 g=3.520\n",
      ">5, 11/50, d1=0.050, d2=0.043 g=3.468\n",
      ">5, 12/50, d1=0.092, d2=0.090 g=3.633\n",
      ">5, 13/50, d1=0.013, d2=0.018 g=4.233\n",
      ">5, 14/50, d1=0.019, d2=0.012 g=4.094\n",
      ">5, 15/50, d1=0.475, d2=0.363 g=4.158\n",
      ">5, 16/50, d1=0.111, d2=0.012 g=4.681\n",
      ">5, 17/50, d1=0.557, d2=0.034 g=3.514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">5, 18/50, d1=0.142, d2=0.072 g=3.082\n",
      ">5, 19/50, d1=0.112, d2=0.079 g=3.192\n",
      ">5, 20/50, d1=0.187, d2=0.142 g=3.334\n",
      ">5, 21/50, d1=0.159, d2=0.075 g=3.437\n",
      ">5, 22/50, d1=0.057, d2=0.067 g=3.520\n",
      ">5, 23/50, d1=0.034, d2=0.060 g=3.750\n",
      ">5, 24/50, d1=0.073, d2=0.030 g=3.808\n",
      ">5, 25/50, d1=0.123, d2=0.073 g=3.540\n",
      ">5, 26/50, d1=0.037, d2=0.046 g=3.813\n",
      ">5, 27/50, d1=0.023, d2=0.034 g=4.137\n",
      ">5, 28/50, d1=0.066, d2=0.029 g=3.882\n",
      ">5, 29/50, d1=0.168, d2=0.074 g=3.458\n",
      ">5, 30/50, d1=0.001, d2=0.036 g=4.131\n",
      ">5, 31/50, d1=0.072, d2=0.027 g=3.894\n",
      ">5, 32/50, d1=0.030, d2=0.027 g=4.170\n",
      ">5, 33/50, d1=0.017, d2=0.034 g=4.130\n",
      ">5, 34/50, d1=0.031, d2=0.020 g=4.505\n",
      ">5, 35/50, d1=0.036, d2=0.018 g=4.138\n",
      ">5, 36/50, d1=0.006, d2=0.028 g=4.029\n",
      ">5, 37/50, d1=0.021, d2=0.027 g=4.439\n",
      ">5, 38/50, d1=0.129, d2=0.057 g=3.827\n",
      ">5, 39/50, d1=0.108, d2=0.206 g=4.773\n",
      ">5, 40/50, d1=0.805, d2=0.030 g=2.593\n",
      ">5, 41/50, d1=0.022, d2=0.251 g=3.789\n",
      ">5, 42/50, d1=0.100, d2=0.023 g=4.286\n",
      ">5, 43/50, d1=0.393, d2=0.036 g=2.994\n",
      ">5, 44/50, d1=0.017, d2=0.081 g=3.149\n",
      ">5, 45/50, d1=0.106, d2=0.070 g=3.179\n",
      ">5, 46/50, d1=0.014, d2=0.056 g=3.512\n",
      ">5, 47/50, d1=0.223, d2=0.070 g=3.626\n",
      ">5, 48/50, d1=0.044, d2=0.028 g=3.556\n",
      ">5, 49/50, d1=0.121, d2=0.111 g=3.638\n",
      ">5, 50/50, d1=0.006, d2=0.028 g=4.080\n"
     ]
    }
   ],
   "source": [
    "model = train(g_model, d_model, gan_model, dataset, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 10, 10, 10], dtype=int8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(dataset[1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 116,\n",
       " 1: 117,\n",
       " 2: 119,\n",
       " 3: 304,\n",
       " 4: 187,\n",
       " 5: 112,\n",
       " 6: 131,\n",
       " 7: 139,\n",
       " 8: 111,\n",
       " 9: 131,\n",
       " 10: 159}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cgan_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate images\n",
    "latent_points, labels = generate_latent_points(100, 110)\n",
    "# specify labels\n",
    "labels = asarray([x for _ in range(10) for x in range(11)])\n",
    "# generate images\n",
    "predictions  = model.predict([latent_points, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1529ccbd0>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(dataset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1529c4710>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "for i in range(10):\n",
    "    imageio.imwrite('output/output_' + str(i) + '.jpg', tf.image.convert_image_dtype(predictions[i], tf.int8).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
